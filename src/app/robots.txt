# See https://www.robotstxt.org/robotstxt.html for documentation on how to use the robots.txt file
#
# To allow all robots to crawl your site, use the following:
# User-agent: *
# Allow: /
#
# To prevent all robots from crawling your site, use the following:
# User-agent: *
# Disallow: /
#
# To prevent certain robots from crawling your site, use the following:
# User-agent: BadBot
# Disallow: /

User-agent: *
Allow: /
Disallow: /admin

Sitemap: https://pod.style/sitemap.xml
